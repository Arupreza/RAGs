Main Idea and Purpose

The study proposes a new privacy-preserving technique called Local Generalization and Bucketization (LGB), which aims to protect personalized privacy in microdata publishing. The motivation is to handle attributes that are considered "semi-sensitive," containing both quasi-identifiers (QI) and sensitive values, reflecting individuals' varied privacy requirements.
Working Principle

LGB operates by independently applying local generalization and local bucketization. Local generalization groups data tuples into local equivalence groups by generalizing only specific quasi-identifier values, while local bucketization divides sensitive values into local buckets within each attribute. This ensures independent and flexible privacy protection tailored to personal preferences.
Workflow

The method follows a two-step workflow: first, it partitions sensitive and semi-sensitive attribute values into local buckets to comply with l-diversity; next, it partitions quasi-identifiers into local equivalence groups to satisfy k-anonymity. This sequential approach ensures both identity and attribute disclosures are prevented effectively.
Methodology

LGB employs two algorithms: local bucketization, which partitions sensitive values into buckets minimizing the range of values; and local generalization, implemented either via multi-dimensional partitioning (LGB_MDP) or by minimizing Normalized Certainty Penalty (NCP) (LGB_NCP). Both approaches aim to balance data utility and privacy protection.
Datasets

The study utilizes the US Census data comprising 31,055 tuples with nine attributes. Attributes are categorized into quasi-identifiers (relationship, marital status, race, education, hours per week), semi-sensitive attributes (sex, age, occupation), and a sensitive attribute (salary).
Key Findings

The experiments demonstrate that LGB effectively satisfies k-anonymity and l-diversity, significantly reducing identity and attribute disclosures. It also shows different strengths for the two local generalization algorithms: LGB_MDP provides evenly distributed equivalence groups, whereas LGB_NCP better preserves information utility by reducing NCP scores.
Advantages

LGB's strength lies in its flexibilityâ€”local generalization and bucketization protections are independent, allowing tailored privacy adjustments per attribute. Additionally, it minimizes information loss by intelligently partitioning data, making it suitable for scenarios demanding personalized privacy preservation.
Limitations

The method's effectiveness can vary depending on the density of sensitive values in semi-sensitive attributes, and its performance is influenced by the selection of anonymization parameters (k, l). Furthermore, protecting attributes with very limited diversity (e.g., gender) requires additional privacy measures (like t-closeness).
Comparison with Related Work

Compared to prior methods such as generalization, bucketization, and slicing, LGB uniquely handles personalized privacy by combining the strengths of local generalization and bucketization. It overcomes generalization's issue of significant information loss and bucketization's limited handling of personalized requirements.
Conclusion

LGB offers a robust framework for personalized privacy protection in data publishing, maintaining high data utility. Future studies are suggested to extend the LGB framework for incremental data publishing scenarios, integrate online learning methods, and consider relationship-based sensitive attributes for enhanced privacy protection
