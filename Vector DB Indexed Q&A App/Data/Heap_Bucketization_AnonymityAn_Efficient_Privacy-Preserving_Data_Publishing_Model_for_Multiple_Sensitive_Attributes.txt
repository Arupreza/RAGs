Main Idea and Purpose:

The primary goal of this study is to introduce Heap Bucketization Anonymity (HBA), a model that effectively anonymizes patient datasets containing multiple sensitive attributes while preserving data utility. The motivation is to mitigate privacy breaches like background knowledge, quasi-identifier, membership, non-membership, and fingerprint correlation attacks, which traditional anonymization models fail to adequately address. The proposed model balances high privacy preservation with minimal utility loss.
Working Principle:

The core mechanism of the HBA model involves anatomizing the dataset into two tables: one for quasi-identifiers and one for sensitive attributes. Quasi-identifiers are anonymized using k-anonymity and slicing, whereas sensitive attributes undergo slicing and Heap Bucketization. Heap Bucketization accumulates all sensitive records from each bucket into a combined heap, making individual record identification nearly impossible and significantly preserving the dataset's utility.
Workflow:

The workflow involves several steps: (1) Data pre-processing, (2) anatomization into quasi-identifier and sensitive attribute tables, (3) calculating correlation among attributes, (4) implementing k-anonymity on quasi-identifier attributes, (5) slicing on sensitive attributes based on correlation, (6) merging both tables, and (7) performing Heap Bucketization, which combines records within each bucket to maximize privacy protection and data utility.
Methodology:

The methodology integrates multiple anonymization techniques. Initially, the dataset is anatomized to separate quasi-identifiers from sensitive attributes. Correlation among attributes is measured using Pearson correlation to identify highly related attributes for slicing. Quasi-identifiers are generalized and k-anonymized, whereas sensitive attributes are sorted into buckets based on disease, sliced according to attribute correlation, and combined into heap buckets to ensure anonymization and utility preservation.
Datasets:

The experimental evaluation utilizes a unique healthcare dataset from the Interdisciplinary Institute of Indian System of Medicine, Ayurveda. The dataset includes 22,527 patient records, each containing quasi-identifiers like age, sex, height, weight, and sensitive attributes such as temperature, pulse rate, respiratory rate, blood pressure, and diseases. This real-world dataset supports the validation of the modelâ€™s effectiveness.
Key Findings:

The HB-anonymity model effectively mitigates privacy risks across five major attacks: background knowledge, quasi-identifier, membership, non-membership, and fingerprint correlation attacks. Experimental results highlight that the model maintains exceptionally low utility loss measured by metrics like Normalized Certainty Penalty (NCP) and KL-divergence, significantly outperforming existing anonymization techniques like (p,k)-angelization and (c,k)-anonymization.
Advantages:

HB-anonymity provides substantial benefits, including superior privacy protection against multiple attack vectors and significantly reduced data utility loss. Its methodical integration of correlation analysis, k-anonymity, slicing, and Heap Bucketization allows it to efficiently handle multiple sensitive attributes. Additionally, it exhibits excellent scalability, consistently low execution time, and negligible utility degradation regardless of dataset size increases.
Limitations:

Although HB-anonymity demonstrates strong privacy and utility performance, it primarily addresses structured, static datasets. Its effectiveness in dynamic datasets or unstructured data scenarios was not fully explored. Another potential limitation is the need for explicit determination and computation of correlations among attributes, which can be computationally intensive for extremely large or high-dimensional datasets.
Comparison with Related Work:

Compared to traditional anonymization models such as (p,k)-angelization and (c,k)-anonymization, HB-anonymity significantly reduces privacy risks and utility loss. The (p,k)-angelization model suffers from higher privacy risks due to vulnerable single-value buckets, whereas (c,k)-anonymization incurs substantial computational overhead and execution time. In contrast, HB-anonymity provides optimal performance, effectively balancing privacy, utility, and computational efficiency.
Conclusion:

The proposed HB-anonymity model successfully addresses privacy preservation challenges in datasets with multiple sensitive attributes, achieving high privacy with minimal utility loss. It effectively counters various privacy threats while maintaining dataset utility, making it a robust solution for healthcare data publishing. Future research directions include extending the model to handle dynamic and unstructured data and exploring the potential to treat quasi-identifiers as semi-sensitive attributes for enhanced privacy protection.
